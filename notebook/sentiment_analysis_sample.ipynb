{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0.1  Unnamed: 0  \\\n0               0           0   \n1               1           1   \n2               2           2   \n3               3           3   \n4               4           4   \n..            ...         ...   \n135           135         135   \n136           136         136   \n137           137         137   \n138           138         138   \n139           139         139   \n\n                                                    DE  SDG  \\\n0    Robotic surgery; thoracic; outcomes; learning-...    3   \n1    Deep learning; Convolutional neural network; C...    3   \n2    Sustainable cities; COVID-19 pandemic; video s...    3   \n3    technology; education; application; augmented ...    3   \n4    Artificial intelligence; Machine learning; Dee...    3   \n..                                                 ...  ...   \n135  global climate model; regional climate model; ...   13   \n136  Lustre file system; I/O performance evaluation...   13   \n137  landscape metrics; forest management; artifici...   13   \n138  data exploration; data visualization; energy p...   13   \n139  sustainable supply chain; Robust optimization;...   13   \n\n                                                    AB     AI  robotics  \\\n0    The number of thoracic surgery cases performed...  False      True   \n1    The COVID-19 pandemic is an emerging respirato...   True     False   \n2    Sustainable smart city initiatives around the ...   True     False   \n3    The use of technology in education is increasi...   True     False   \n4    Colorectal cancer (CRC) was the second-ranked ...   True     False   \n..                                                 ...    ...       ...   \n135  Demonstrating the effect that climate change i...  False     False   \n136  In this paper we study the performance of the ...  False     False   \n137  Plant diversity is a core value of forests and...   True     False   \n138  The energy performance certificate (EPC) is a ...   True     False   \n139  In this paper, the problem of sustainable clos...  False     False   \n\n       IOT  big_data  computing_infrastructure  ...  \\\n0    False     False                     False  ...   \n1    False     False                     False  ...   \n2    False     False                     False  ...   \n3    False     False                     False  ...   \n4    False     False                     False  ...   \n..     ...       ...                       ...  ...   \n135  False     False                      True  ...   \n136  False     False                      True  ...   \n137  False     False                     False  ...   \n138  False     False                     False  ...   \n139  False      True                     False  ...   \n\n                                            Term4  Term5 Annotator  \\\n0                                             NaN    NaN   Claudia   \n1      ('Neural Network', '0.03', '0.38', '0.59')    NaN   Claudia   \n2                                             NaN    NaN   Claudia   \n3                                             NaN    NaN   Claudia   \n4    ('Machine learning', '0.05', '0.23', '0.73')    NaN   Claudia   \n..                                            ...    ...       ...   \n135                                           NaN    NaN     Kevin   \n136                                           NaN    NaN     Kevin   \n137                                           NaN    NaN     Kevin   \n138                                           NaN    NaN     Kevin   \n139                                           NaN    NaN     Kevin   \n\n    manual_sent roberta_sent vader_sent_compound vader_sent trans_sent  \\\n0           Pos          Pos              0.9799        Pos        Neu   \n1           Pos          Pos              0.9076        Pos        Neu   \n2           Pos          Pos              0.9912        Pos        Neu   \n3           Pos          Neu              0.6486        Pos        Neu   \n4           Pos          Pos             -0.7717        Neg        Neu   \n..          ...          ...                 ...        ...        ...   \n135         Pos          Pos              0.8591        Pos        Neu   \n136         Neu          Neu              0.9477        Pos        Neu   \n137         Neu          Pos              0.8100        Pos        Neu   \n138         Pos          Pos              0.9887        Pos        Neu   \n139         Pos          Pos              0.8759        Pos        Neu   \n\n    SentiBigNomics senti_sent  \n0         0.000000        Neu  \n1         0.191056        Neu  \n2         0.379250        Pos  \n3         0.000000        Neu  \n4         0.391800        Pos  \n..             ...        ...  \n135       0.000000        Neu  \n136       0.194118        Neu  \n137       0.000000        Neu  \n138       0.000000        Neu  \n139       0.000000        Neu  \n\n[140 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0.1</th>\n      <th>Unnamed: 0</th>\n      <th>DE</th>\n      <th>SDG</th>\n      <th>AB</th>\n      <th>AI</th>\n      <th>robotics</th>\n      <th>IOT</th>\n      <th>big_data</th>\n      <th>computing_infrastructure</th>\n      <th>...</th>\n      <th>Term4</th>\n      <th>Term5</th>\n      <th>Annotator</th>\n      <th>manual_sent</th>\n      <th>roberta_sent</th>\n      <th>vader_sent_compound</th>\n      <th>vader_sent</th>\n      <th>trans_sent</th>\n      <th>SentiBigNomics</th>\n      <th>senti_sent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>Robotic surgery; thoracic; outcomes; learning-...</td>\n      <td>3</td>\n      <td>The number of thoracic surgery cases performed...</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Claudia</td>\n      <td>Pos</td>\n      <td>Pos</td>\n      <td>0.9799</td>\n      <td>Pos</td>\n      <td>Neu</td>\n      <td>0.000000</td>\n      <td>Neu</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>Deep learning; Convolutional neural network; C...</td>\n      <td>3</td>\n      <td>The COVID-19 pandemic is an emerging respirato...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>('Neural Network', '0.03', '0.38', '0.59')</td>\n      <td>NaN</td>\n      <td>Claudia</td>\n      <td>Pos</td>\n      <td>Pos</td>\n      <td>0.9076</td>\n      <td>Pos</td>\n      <td>Neu</td>\n      <td>0.191056</td>\n      <td>Neu</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>2</td>\n      <td>Sustainable cities; COVID-19 pandemic; video s...</td>\n      <td>3</td>\n      <td>Sustainable smart city initiatives around the ...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Claudia</td>\n      <td>Pos</td>\n      <td>Pos</td>\n      <td>0.9912</td>\n      <td>Pos</td>\n      <td>Neu</td>\n      <td>0.379250</td>\n      <td>Pos</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>3</td>\n      <td>technology; education; application; augmented ...</td>\n      <td>3</td>\n      <td>The use of technology in education is increasi...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Claudia</td>\n      <td>Pos</td>\n      <td>Neu</td>\n      <td>0.6486</td>\n      <td>Pos</td>\n      <td>Neu</td>\n      <td>0.000000</td>\n      <td>Neu</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n      <td>Artificial intelligence; Machine learning; Dee...</td>\n      <td>3</td>\n      <td>Colorectal cancer (CRC) was the second-ranked ...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>('Machine learning', '0.05', '0.23', '0.73')</td>\n      <td>NaN</td>\n      <td>Claudia</td>\n      <td>Pos</td>\n      <td>Pos</td>\n      <td>-0.7717</td>\n      <td>Neg</td>\n      <td>Neu</td>\n      <td>0.391800</td>\n      <td>Pos</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>135</th>\n      <td>135</td>\n      <td>135</td>\n      <td>global climate model; regional climate model; ...</td>\n      <td>13</td>\n      <td>Demonstrating the effect that climate change i...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Kevin</td>\n      <td>Pos</td>\n      <td>Pos</td>\n      <td>0.8591</td>\n      <td>Pos</td>\n      <td>Neu</td>\n      <td>0.000000</td>\n      <td>Neu</td>\n    </tr>\n    <tr>\n      <th>136</th>\n      <td>136</td>\n      <td>136</td>\n      <td>Lustre file system; I/O performance evaluation...</td>\n      <td>13</td>\n      <td>In this paper we study the performance of the ...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Kevin</td>\n      <td>Neu</td>\n      <td>Neu</td>\n      <td>0.9477</td>\n      <td>Pos</td>\n      <td>Neu</td>\n      <td>0.194118</td>\n      <td>Neu</td>\n    </tr>\n    <tr>\n      <th>137</th>\n      <td>137</td>\n      <td>137</td>\n      <td>landscape metrics; forest management; artifici...</td>\n      <td>13</td>\n      <td>Plant diversity is a core value of forests and...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Kevin</td>\n      <td>Neu</td>\n      <td>Pos</td>\n      <td>0.8100</td>\n      <td>Pos</td>\n      <td>Neu</td>\n      <td>0.000000</td>\n      <td>Neu</td>\n    </tr>\n    <tr>\n      <th>138</th>\n      <td>138</td>\n      <td>138</td>\n      <td>data exploration; data visualization; energy p...</td>\n      <td>13</td>\n      <td>The energy performance certificate (EPC) is a ...</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Kevin</td>\n      <td>Pos</td>\n      <td>Pos</td>\n      <td>0.9887</td>\n      <td>Pos</td>\n      <td>Neu</td>\n      <td>0.000000</td>\n      <td>Neu</td>\n    </tr>\n    <tr>\n      <th>139</th>\n      <td>139</td>\n      <td>139</td>\n      <td>sustainable supply chain; Robust optimization;...</td>\n      <td>13</td>\n      <td>In this paper, the problem of sustainable clos...</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Kevin</td>\n      <td>Pos</td>\n      <td>Pos</td>\n      <td>0.8759</td>\n      <td>Pos</td>\n      <td>Neu</td>\n      <td>0.000000</td>\n      <td>Neu</td>\n    </tr>\n  </tbody>\n</table>\n<p>140 rows × 27 columns</p>\n</div>"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = pd.read_excel(\"../data/sample_fully_annotated.xlsx\")\n",
    "df_sample"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "# Vader stuff\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "# for sentence in df_sample.AB:\n",
    "#     vs = analyzer.polarity_scores(sentence)\n",
    "#     # print(\"{:-<65} {}\".format(sentence, str(vs)))\n",
    "#     print(vs)\n",
    "df_sample['vader_sent_compound'] = df_sample['AB'].apply(lambda x:analyzer.polarity_scores(x)['compound'])\n",
    "dic_vader = {}\n",
    "df_sample['vader_sent'] = np.where(df_sample['vader_sent_compound'] > 0.6, 'Pos', (np.where(df_sample['vader_sent_compound'] > -0.6, 'Neu', 'Neg')))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "def compute_accuracy_recall_f1(sent, manual_sent, model_sent):\n",
    "    size = len(manual_sent)\n",
    "    tot_correct_annot = 0\n",
    "    tot_annot = 0\n",
    "    tot_manual = 0\n",
    "    for i in range(size):\n",
    "        if manual_sent[i] == sent:\n",
    "            tot_manual += 1\n",
    "            if model_sent[i] == sent:\n",
    "                tot_correct_annot += 1\n",
    "        if model_sent[i] == sent:\n",
    "            tot_annot += 1\n",
    "\n",
    "    precision = tot_correct_annot / tot_annot\n",
    "    recall = tot_correct_annot / tot_manual\n",
    "    fscore = 2 * precision * recall / (precision + recall) if (precision+recall) != 0 else 0\n",
    "\n",
    "    return sent, round(precision, 2), round(recall,2 ), round(fscore, 2), tot_correct_annot, tot_manual, tot_annot\n",
    "\n",
    "def compute_acc(manual_sent, model_sent):\n",
    "    tot_correct = 0\n",
    "    size = len(manual_sent)\n",
    "    for i in range(size):\n",
    "        if manual_sent[i] == model_sent[i]:\n",
    "            tot_correct += 1\n",
    "    return round(tot_correct/size, 2)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Other sent analysis\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load a traditional Sentiment Analysis model\n",
    "sentiment_model_path = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "sentiment_model = pipeline(\"sentiment-analysis\", model=sentiment_model_path,\n",
    "                           tokenizer=sentiment_model_path)\n",
    "\n",
    "dic_sent = {\"neutral\": \"Neu\", \"positive\": \"Pos\", \"negative\":'Neg'}\n",
    "lst_label = []\n",
    "lst_score = []\n",
    "for ind, row in df_sample.iterrows():\n",
    "    txt = row.AB[-2000:]\n",
    "    sent = sentiment_model([txt])[0]\n",
    "    label = sent['label']\n",
    "    score = sent['score']\n",
    "    lst_label.append(dic_sent[label])\n",
    "    lst_score.append(score)\n",
    "df_sample['trans_sent'] = lst_label\n",
    "df_sample.to_excel(\"../data/sample_fully_annotated.xlsx\")\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "lst_manual = df_sample.manual_sent.to_list()\n",
    "dic_tool = {\n",
    "\"vader\" : df_sample.vader_sent.to_list(),\n",
    "\"roberta\" : df_sample.roberta_sent.to_list(),\n",
    "\"base\" : df_sample.trans_sent.to_list(),\n",
    "\"senti\" : df_sample.senti_sent.to_list(),\n",
    "}\n",
    "\n",
    "lst = []\n",
    "\n",
    "for tool in dic_tool:\n",
    "    for sent in ['Neg', 'Neu', 'Pos']:\n",
    "        res = [tool]+list(compute_accuracy_recall_f1(sent=sent, manual_sent=lst_manual, model_sent=dic_tool[tool])) + [(compute_acc(manual_sent=lst_manual, model_sent=dic_tool[tool]))]\n",
    "        lst.append(res)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [
    {
     "data": {
      "text/plain": "          Precision             Recall             F1score              \\\nSentiment       Neg   Neu   Pos    Neg   Neu   Pos     Neg   Neu   Pos   \nTool                                                                     \nbase           0.40  0.37  0.00   0.50  0.96  0.00    0.44  0.54  0.00   \nroberta        0.33  0.60  0.76   0.50  0.54  0.79    0.40  0.57  0.77   \nsenti          0.00  0.41  0.77   0.00  0.87  0.24    0.00  0.55  0.36   \nvader          0.08  0.32  0.62   0.25  0.13  0.77    0.12  0.19  0.69   \n\n          total_correct  ...     total_manual         total_annotated       \\\nSentiment           Neg  ... Pos          Neg Neu Pos             Neg  Neu   \nTool                     ...                                                 \nbase                  2  ...   0            4  52  84               5  134   \nroberta               2  ...  66            4  52  84               6   47   \nsenti                 0  ...  20            4  52  84               3  111   \nvader                 1  ...  65            4  52  84              13   22   \n\n               overall_accuracy              \nSentiment  Pos              Neg   Neu   Pos  \nTool                                         \nbase         1             0.37  0.37  0.37  \nroberta     87             0.69  0.69  0.69  \nsenti       26             0.46  0.46  0.46  \nvader      105             0.52  0.52  0.52  \n\n[4 rows x 21 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th colspan=\"3\" halign=\"left\">Precision</th>\n      <th colspan=\"3\" halign=\"left\">Recall</th>\n      <th colspan=\"3\" halign=\"left\">F1score</th>\n      <th colspan=\"3\" halign=\"left\">total_correct</th>\n      <th colspan=\"3\" halign=\"left\">total_manual</th>\n      <th colspan=\"3\" halign=\"left\">total_annotated</th>\n      <th colspan=\"3\" halign=\"left\">overall_accuracy</th>\n    </tr>\n    <tr>\n      <th>Sentiment</th>\n      <th>Neg</th>\n      <th>Neu</th>\n      <th>Pos</th>\n      <th>Neg</th>\n      <th>Neu</th>\n      <th>Pos</th>\n      <th>Neg</th>\n      <th>Neu</th>\n      <th>Pos</th>\n      <th>Neg</th>\n      <th>...</th>\n      <th>Pos</th>\n      <th>Neg</th>\n      <th>Neu</th>\n      <th>Pos</th>\n      <th>Neg</th>\n      <th>Neu</th>\n      <th>Pos</th>\n      <th>Neg</th>\n      <th>Neu</th>\n      <th>Pos</th>\n    </tr>\n    <tr>\n      <th>Tool</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>base</th>\n      <td>0.40</td>\n      <td>0.37</td>\n      <td>0.00</td>\n      <td>0.50</td>\n      <td>0.96</td>\n      <td>0.00</td>\n      <td>0.44</td>\n      <td>0.54</td>\n      <td>0.00</td>\n      <td>2</td>\n      <td>...</td>\n      <td>0</td>\n      <td>4</td>\n      <td>52</td>\n      <td>84</td>\n      <td>5</td>\n      <td>134</td>\n      <td>1</td>\n      <td>0.37</td>\n      <td>0.37</td>\n      <td>0.37</td>\n    </tr>\n    <tr>\n      <th>roberta</th>\n      <td>0.33</td>\n      <td>0.60</td>\n      <td>0.76</td>\n      <td>0.50</td>\n      <td>0.54</td>\n      <td>0.79</td>\n      <td>0.40</td>\n      <td>0.57</td>\n      <td>0.77</td>\n      <td>2</td>\n      <td>...</td>\n      <td>66</td>\n      <td>4</td>\n      <td>52</td>\n      <td>84</td>\n      <td>6</td>\n      <td>47</td>\n      <td>87</td>\n      <td>0.69</td>\n      <td>0.69</td>\n      <td>0.69</td>\n    </tr>\n    <tr>\n      <th>senti</th>\n      <td>0.00</td>\n      <td>0.41</td>\n      <td>0.77</td>\n      <td>0.00</td>\n      <td>0.87</td>\n      <td>0.24</td>\n      <td>0.00</td>\n      <td>0.55</td>\n      <td>0.36</td>\n      <td>0</td>\n      <td>...</td>\n      <td>20</td>\n      <td>4</td>\n      <td>52</td>\n      <td>84</td>\n      <td>3</td>\n      <td>111</td>\n      <td>26</td>\n      <td>0.46</td>\n      <td>0.46</td>\n      <td>0.46</td>\n    </tr>\n    <tr>\n      <th>vader</th>\n      <td>0.08</td>\n      <td>0.32</td>\n      <td>0.62</td>\n      <td>0.25</td>\n      <td>0.13</td>\n      <td>0.77</td>\n      <td>0.12</td>\n      <td>0.19</td>\n      <td>0.69</td>\n      <td>1</td>\n      <td>...</td>\n      <td>65</td>\n      <td>4</td>\n      <td>52</td>\n      <td>84</td>\n      <td>13</td>\n      <td>22</td>\n      <td>105</td>\n      <td>0.52</td>\n      <td>0.52</td>\n      <td>0.52</td>\n    </tr>\n  </tbody>\n</table>\n<p>4 rows × 21 columns</p>\n</div>"
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res = pd.DataFrame(data=lst, columns=['Tool', 'Sentiment', \"Precision\", 'Recall', 'F1score', 'total_correct', 'total_manual', 'total_annotated', 'overall_accuracy'])\n",
    "df_res.pivot(index=\"Tool\", columns='Sentiment')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "df_res.set_index(['Tool', 'Sentiment']).to_excel(\"../results/score.xlsx\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
